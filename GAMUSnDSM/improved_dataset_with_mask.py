import os
import json
import numpy as np
import torch
from torch.utils.data import Dataset
from torchvision import transforms
import cv2
import logging
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
import warnings
from improved_normalization_loss import HeightNormalizer

warnings.filterwarnings('ignore')

class GAMUSDataset(Dataset):
    """å¸¦maskåŠŸèƒ½çš„GAMUS nDSMæ•°æ®é›†åŠ è½½å™¨"""
    
    def __init__(self, 
                 image_dir: str, 
                 label_dir: str, 
                 mask_dir: Optional[str] = None,  # æ–°å¢ï¼šmaskç›®å½•
                 building_class_id: int = 6,      # æ–°å¢ï¼šå»ºç­‘ç±»åˆ«ID
                 tree_class_id: int = 5,          # æ–°å¢ï¼šæ ‘æœ¨ç±»åˆ«ID
                 normalization_method: str = 'percentile',
                 enable_augmentation: bool = False,
                 stats_json_path: Optional[str] = None,
                 height_filter: Optional[Dict[str, float]] = None,
                 force_recompute: bool = False):
        """
        åˆå§‹åŒ–GAMUSæ•°æ®é›†
        
        å‚æ•°:
            image_dir: å½±åƒåˆ‡ç‰‡ç›®å½•
            label_dir: nDSMæ ‡ç­¾åˆ‡ç‰‡ç›®å½•  
            mask_dir: classes maskç›®å½• (æ–°å¢)
            building_class_id: å»ºç­‘ç±»åˆ«ID (æ–°å¢)
            tree_class_id: æ ‘æœ¨ç±»åˆ«ID (æ–°å¢)
            normalization_method: å½’ä¸€åŒ–æ–¹æ³• ('percentile', 'minmax', 'zscore')
            enable_augmentation: æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º
            stats_json_path: é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„
            height_filter: é«˜åº¦è¿‡æ»¤é…ç½® {'min_height': -5.0, 'max_height': 100.0}
            force_recompute: æ˜¯å¦å¼ºåˆ¶é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        """
        # âœ… æ·»åŠ loggeråˆå§‹åŒ–
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # åœ¨__init__æœ€å¼€å§‹æ·»åŠ 
        if not stats_json_path:
            raise ValueError("å¿…é¡»æŒ‡å®šstats_json_pathå‚æ•°ï¼Œè¯·å…ˆè¿è¡Œé¢„è®¡ç®—è„šæœ¬")

        if not os.path.exists(stats_json_path):
            raise FileNotFoundError(f"ç»Ÿè®¡ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {stats_json_path}ï¼Œè¯·å…ˆè¿è¡Œ: python precompute_stats.py {image_dir}/../..")
        
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.mask_dir = mask_dir  # æ–°å¢
        self.building_class_id = building_class_id  # æ–°å¢
        self.tree_class_id = tree_class_id  # æ–°å¢
        self.use_mask = mask_dir is not None  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨mask
        
        self.normalization_method = normalization_method
        self.enable_augmentation = enable_augmentation
        self.stats_json_path = stats_json_path
        self.force_recompute = force_recompute

        # è®¾ç½®é«˜åº¦è¿‡æ»¤å™¨ï¼ˆé»˜è®¤åˆç†èŒƒå›´ï¼‰
        self.height_filter = height_filter or {'min_height': -5.0, 'max_height': 200.0}
        
        # éªŒè¯ç›®å½•
        self._validate_directories()
        
        # è·å–æ–‡ä»¶å¯¹
        self.file_pairs = self._get_file_pairs()
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯å’Œå½’ä¸€åŒ–å™¨
        self._initialize_normalizer()
        
        # è®¾ç½®æ•°æ®å˜æ¢
        self.transform = self._setup_transforms()
        
        self.logger.info(f"GAMUSæ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(self.file_pairs)} ä¸ªæ ·æœ¬")
        if self.use_mask:
            self.logger.info(f"å¯ç”¨maskåŠŸèƒ½ - å»ºç­‘ç±»åˆ«ID: {building_class_id}, æ ‘æœ¨ç±»åˆ«ID: {tree_class_id}")
     
    def _validate_directories(self):
        """éªŒè¯ç›®å½•å­˜åœ¨æ€§"""
        if not os.path.exists(self.image_dir):
            raise FileNotFoundError(f"å½±åƒç›®å½•ä¸å­˜åœ¨: {self.image_dir}")
        if not os.path.exists(self.label_dir):
            raise FileNotFoundError(f"nDSMæ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {self.label_dir}")
        
        # æ–°å¢ï¼šéªŒè¯maskç›®å½•
        if self.use_mask and not os.path.exists(self.mask_dir):
            raise FileNotFoundError(f"Maskç›®å½•ä¸å­˜åœ¨: {self.mask_dir}")
    
    def _get_file_pairs(self):
        """è·å–åŒ¹é…çš„æ–‡ä»¶å¯¹ï¼ˆåŒ…æ‹¬maskï¼‰"""
        # è·å–æ–‡ä»¶åˆ—è¡¨
        image_files = [f for f in os.listdir(self.image_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff'))]
        label_files = [f for f in os.listdir(self.label_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff'))]
        
        # æ–°å¢ï¼šè·å–maskæ–‡ä»¶åˆ—è¡¨
        mask_files = []
        if self.use_mask:
            mask_files = [f for f in os.listdir(self.mask_dir) 
                         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff'))]
        
        # åˆ›å»ºåŒ¹é…æ˜ å°„
        image_dict = {}
        label_dict = {}
        mask_dict = {}  # æ–°å¢
        
        # å¤„ç†å›¾åƒæ–‡ä»¶
        for img_file in image_files:
            if '_RGB_' in img_file:
                base_name = img_file.replace('_RGB_', '_').rsplit('.', 1)[0]
            else:
                base_name = Path(img_file).stem
            image_dict[base_name] = img_file
        
        # å¤„ç†æ ‡ç­¾æ–‡ä»¶  
        for label_file in label_files:
            if '_AGL_' in label_file:
                base_name = label_file.replace('_AGL_', '_').rsplit('.', 1)[0]
            else:
                base_name = Path(label_file).stem
            label_dict[base_name] = label_file
        
        # æ–°å¢ï¼šå¤„ç†maskæ–‡ä»¶
        if self.use_mask:
            for mask_file in mask_files:
                # å‡è®¾maskæ–‡ä»¶æ ¼å¼ç±»ä¼¼ï¼šDC_02_26_classes_r0c0.png
                if '_classes_' in mask_file:
                    base_name = mask_file.replace('_classes_', '_').rsplit('.', 1)[0]
                elif '_CLS_' in mask_file:
                    base_name = mask_file.replace('_CLS_', '_').rsplit('.', 1)[0]
                else:
                    base_name = Path(mask_file).stem
                mask_dict[base_name] = mask_file
        
        # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹
        matched_pairs = []
        for base_name in image_dict:
            if base_name in label_dict:
                if self.use_mask:
                    # éœ€è¦åŒæ—¶åŒ¹é…maskæ–‡ä»¶
                    if base_name in mask_dict:
                        matched_pairs.append((image_dict[base_name], label_dict[base_name], mask_dict[base_name]))
                else:
                    # ä¸ä½¿ç”¨maskæ—¶ï¼Œç¬¬ä¸‰ä¸ªå…ƒç´ ä¸ºNone
                    matched_pairs.append((image_dict[base_name], label_dict[base_name], None))
        
        if not matched_pairs:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„æ–‡ä»¶å¯¹")
        
        logging.info(f"æˆåŠŸåŒ¹é… {len(matched_pairs)} ä¸ªæ–‡ä»¶å¯¹")
        if self.use_mask:
            logging.info(f"åŒ…å«maskæ–‡ä»¶: {sum(1 for _, _, mask in matched_pairs if mask is not None)} ä¸ª")
        
        return matched_pairs
    
    def _initialize_normalizer(self):
        """åˆå§‹åŒ–å½’ä¸€åŒ–å™¨"""
        # å°è¯•ä»JSONåŠ è½½ç»Ÿè®¡ä¿¡æ¯
        if self.stats_json_path and os.path.exists(self.stats_json_path):
            self.logger.info(f"ğŸ”„ åŠ è½½é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯: {self.stats_json_path}")
            if self._load_from_json():
                self.logger.info("âœ… æˆåŠŸåŠ è½½é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼Œè·³è¿‡é‡æ–°è®¡ç®—")
                return
            else:
                self.logger.warning("âš ï¸ é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯åŠ è½½å¤±è´¥")
        
        # å¦‚æœå¼ºåˆ¶é‡æ–°è®¡ç®—æˆ–æ²¡æœ‰é¢„è®¡ç®—æ–‡ä»¶
        if self.force_recompute or not self.stats_json_path or not os.path.exists(self.stats_json_path):
            self.logger.error("âŒ æ²¡æœ‰é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ä¸”ç¦ç”¨å®æ—¶è®¡ç®—")
            self.logger.info("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python precompute_stats.py <data_dir>")
            raise ValueError("éœ€è¦å…ˆè¿è¡Œé¢„è®¡ç®—è„šæœ¬ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯")
    
    def _load_from_json(self) -> bool:
        """ä»JSONæ–‡ä»¶åŠ è½½ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with open(self.stats_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # éªŒè¯JSONæ ¼å¼
            if 'global_statistics' not in data:
                logging.warning("JSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                return False
            
            stats = data['global_statistics']
            
            # åŠ è½½åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            self.global_min = float(stats['min'])
            self.global_max = float(stats['max'])
            self.global_mean = float(stats['mean'])
            self.global_std = float(stats['std'])
            
            # åº”ç”¨é«˜åº¦è¿‡æ»¤
            precomputed_filter = data.get('processing_info', {}).get('height_filter', {})
            if (precomputed_filter.get('min_height') != self.height_filter['min_height'] or 
                precomputed_filter.get('max_height') != self.height_filter['max_height']):
                self.logger.warning(f"âš ï¸ é«˜åº¦è¿‡æ»¤è®¾ç½®ä¸é¢„è®¡ç®—ä¸ä¸€è‡´")
                self.logger.warning(f"   é¢„è®¡ç®—: {precomputed_filter}")
                self.logger.warning(f"   å½“å‰è®¾ç½®: {self.height_filter}")

            original_min, original_max = self.global_min, self.global_max
            self.global_min = max(self.global_min, self.height_filter['min_height'])
            self.global_max = min(self.global_max, self.height_filter['max_height'])
            
            if self.global_min != original_min or self.global_max != original_max:
                self.logger.info(f"åº”ç”¨é«˜åº¦è¿‡æ»¤: [{original_min:.1f}, {original_max:.1f}] -> [{self.global_min:.1f}, {self.global_max:.1f}]")
            
            # åˆ›å»ºå½’ä¸€åŒ–å™¨
            self.height_normalizer = HeightNormalizer(self.normalization_method)
            
            # ä½¿ç”¨è¿‡æ»¤åçš„èŒƒå›´é‡æ–°æ‹Ÿåˆå½’ä¸€åŒ–å™¨
            dummy_data = np.linspace(self.global_min, self.global_max, 1000)
            self.height_normalizer.fit(dummy_data)
            
            # è¾“å‡ºåŠ è½½çš„ç»Ÿè®¡ä¿¡æ¯
            processing_info = data.get('processing_info', {})
            self.logger.info(f"ğŸ“Š åŠ è½½ç»Ÿè®¡ä¿¡æ¯:")
            self.logger.info(f"   æ•°æ®èŒƒå›´: [{self.global_min:.2f}, {self.global_max:.2f}] ç±³")
            self.logger.info(f"   å¤„ç†æ–‡ä»¶: {processing_info.get('processed_files', '?')} ä¸ª")
            self.logger.info(f"   æ•°æ®ç‚¹æ•°: {stats.get('total_samples', '?'):,}")
            return True
            
        except Exception as e:
            self.logger.error(f"åŠ è½½JSONç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def _get_valid_mask(self, data):
        """è·å–æœ‰æ•ˆæ•°æ®æ©ç """
        invalid_values = [-9999, -32768, 9999, 32767]
        valid_mask = ~(np.isnan(data) | np.isinf(data))
        
        for invalid_val in invalid_values:
            valid_mask = valid_mask & (data != invalid_val)
        
        return valid_mask
    
    def _setup_transforms(self):
        """è®¾ç½®æ•°æ®å˜æ¢"""
        transform_list = []
        
        if self.enable_augmentation:
            transform_list.extend([
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomVerticalFlip(p=0.5),
                transforms.ColorJitter(brightness=0.03, contrast=0.03, saturation=0.03, hue=0.01),
                transforms.RandomRotation(degrees=5, fill=0),
            ])
        
        transform_list.append(
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        )
        
        return transforms.Compose(transform_list)
    
    # æ–°å¢ï¼šåˆ›å»ºbuilding+tree mask
    def _create_mask(self, class_image):
        """
        ä»classeså›¾åƒåˆ›å»ºbuilding+treeçš„äºŒå€¼mask
        
        å‚æ•°:
            class_image: classeså›¾åƒ (H, W)
        
        è¿”å›:
            mask: äºŒå€¼maskï¼Œ1è¡¨ç¤ºbuildingæˆ–treeï¼Œ0è¡¨ç¤ºå…¶ä»– (H, W)
        """
        mask = np.zeros_like(class_image, dtype=np.float32)
        
        # åˆ›å»ºbuildingå’Œtreeçš„mask
        building_mask = (class_image == self.building_class_id)
        tree_mask = (class_image == self.tree_class_id)
        
        # åˆå¹¶mask
        combined_mask = building_mask | tree_mask
        mask[combined_mask] = 1.0
        
        return mask
    
    def __len__(self):
        return len(self.file_pairs)
    
    def __getitem__(self, idx):
        """è·å–å•ä¸ªæ ·æœ¬ï¼ˆåŒ…æ‹¬maskï¼‰"""
        try:
            if self.use_mask:
                image_file, label_file, mask_file = self.file_pairs[idx]
            else:
                image_file, label_file, mask_file = self.file_pairs[idx][0], self.file_pairs[idx][1], None
            
            # åŠ è½½å½±åƒ
            image = self._load_image(os.path.join(self.image_dir, image_file))
            
            # åŠ è½½nDSMæ ‡ç­¾
            label = self._load_label(os.path.join(self.label_dir, label_file))
            
            # æ–°å¢ï¼šåŠ è½½mask
            mask = None
            if self.use_mask and mask_file:
                mask = self._load_mask(os.path.join(self.mask_dir, mask_file))
            
            # è½¬æ¢ä¸ºtensor
            image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()
            label_tensor = torch.from_numpy(label).float()
            
            # åº”ç”¨å˜æ¢
            if self.transform:
                image_tensor = self.transform(image_tensor)
            
            # æ–°å¢ï¼šè¿”å›mask
            if self.use_mask and mask is not None:
                mask_tensor = torch.from_numpy(mask).float()
                return image_tensor, label_tensor, mask_tensor
            else:
                # å¦‚æœä¸ä½¿ç”¨maskï¼Œè¿”å›å…¨1çš„maskï¼ˆè¡¨ç¤ºæ‰€æœ‰åƒç´ éƒ½å‚ä¸è®­ç»ƒï¼‰
                dummy_mask = torch.ones_like(label_tensor)
                return image_tensor, label_tensor, dummy_mask
            
        except Exception as e:
            logging.error(f"åŠ è½½æ ·æœ¬ {idx} å¤±è´¥: {e}")
            # è¿”å›ä¸‹ä¸€ä¸ªæ ·æœ¬
            return self.__getitem__((idx + 1) % len(self.file_pairs))
    
    def _load_image(self, image_path):
        """åŠ è½½å½±åƒæ–‡ä»¶"""
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å½±åƒ: {image_path}")
        
        # é¢œè‰²ç©ºé—´è½¬æ¢å’Œå½’ä¸€åŒ–
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)
        
        # è°ƒæ•´å¤§å°
        if image.shape[:2] != (448, 448):
            image = cv2.resize(image, (448, 448), interpolation=cv2.INTER_CUBIC)
        
        # å½’ä¸€åŒ–åˆ°[0,1]
        if image.max() > 1:
            image = image / 255.0
        
        return image
    
    def _load_label(self, label_path):
        """åŠ è½½nDSMæ ‡ç­¾æ–‡ä»¶"""
        label = cv2.imread(label_path, cv2.IMREAD_UNCHANGED)
        if label is None:
            raise ValueError(f"æ— æ³•åŠ è½½nDSMæ ‡ç­¾: {label_path}")
        
        label = label.astype(np.float32)
        
        # è°ƒæ•´å¤§å°
        if label.shape != (448, 448):
            label = cv2.resize(label, (448, 448), interpolation=cv2.INTER_LINEAR)
        
        # å¤„ç†æ— æ•ˆå€¼
        INVALID_MARKER = -999.0
        valid_mask = self._get_valid_mask(label)
        
        # æ ‡è®°æ— æ•ˆå€¼
        label[~valid_mask] = INVALID_MARKER
        
        # å•ä½è½¬æ¢ï¼šå˜ç±³è½¬ç±³
        label[valid_mask] = label[valid_mask] / 100.0
        
        # åº”ç”¨é«˜åº¦è¿‡æ»¤
        height_valid_mask = (
            (label >= self.height_filter['min_height']) & 
            (label <= self.height_filter['max_height'])
        )
        
        # åˆ›å»ºæœ€ç»ˆçš„æœ‰æ•ˆæ©ç 
        final_valid_mask = valid_mask & height_valid_mask
        
        # å½’ä¸€åŒ–
        normalized_label = np.full_like(label, -1.0)  # æ— æ•ˆå€¼æ ‡è®°ä¸º-1
        
        if np.any(final_valid_mask):
            valid_heights = label[final_valid_mask]
            normalized_heights = self.height_normalizer.normalize(valid_heights)
            normalized_label[final_valid_mask] = np.clip(normalized_heights, 0, 1)
        
        return normalized_label
    
    # æ–°å¢ï¼šåŠ è½½maskæ–‡ä»¶
    def _load_mask(self, mask_path):
        """åŠ è½½classes maskæ–‡ä»¶"""
        mask_image = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
        if mask_image is None:
            raise ValueError(f"æ— æ³•åŠ è½½mask: {mask_path}")
        
        # å¦‚æœæ˜¯å¤šé€šé“ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“
        if len(mask_image.shape) == 3:
            mask_image = mask_image[:, :, 0]
        
        mask_image = mask_image.astype(np.uint8)
        
        # è°ƒæ•´å¤§å°
        if mask_image.shape != (448, 448):
            mask_image = cv2.resize(mask_image, (448, 448), interpolation=cv2.INTER_NEAREST)
        
        # åˆ›å»ºbuilding+tree mask
        mask = self._create_mask(mask_image)
        
        return mask
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'min_height': self.global_min,
            'max_height': self.global_max,
            'mean_height': self.global_mean,
            'std_height': self.global_std,
            'height_filter': self.height_filter,
            'normalization_method': self.normalization_method,
            'total_samples': len(self.file_pairs),
            'use_mask': self.use_mask,
            'building_class_id': self.building_class_id if self.use_mask else None,
            'tree_class_id': self.tree_class_id if self.use_mask else None
        }
    
    def get_normalizer(self):
        """è·å–å½’ä¸€åŒ–å™¨"""
        return self.height_normalizer


# ä¿®æ”¹åçš„ä¾¿åˆ©å‡½æ•°
def create_gamus_dataloader(image_dir, label_dir, batch_size=8, shuffle=True, 
                           normalization_method='percentile', enable_augmentation=False,
                           stats_json_path=None, height_filter=None, 
                           force_recompute=False, num_workers=4,
                           mask_dir=None, building_class_id=6, tree_class_id=5):  # æ–°å¢å‚æ•°
    """
    åˆ›å»ºGAMUSæ•°æ®åŠ è½½å™¨
    
    å‚æ•°:
        image_dir: å½±åƒç›®å½•
        label_dir: æ ‡ç­¾ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        normalization_method: å½’ä¸€åŒ–æ–¹æ³•
        enable_augmentation: æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º
        stats_json_path: ç»Ÿè®¡ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„
        height_filter: é«˜åº¦è¿‡æ»¤å™¨ï¼Œä¾‹å¦‚ {'min_height': -5.0, 'max_height': 100.0}
        force_recompute: æ˜¯å¦å¼ºåˆ¶é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        mask_dir: classes maskç›®å½• (æ–°å¢)
        building_class_id: å»ºç­‘ç±»åˆ«ID (æ–°å¢)
        tree_class_id: æ ‘æœ¨ç±»åˆ«ID (æ–°å¢)
    """
    dataset = GAMUSDataset(
        image_dir=image_dir,
        label_dir=label_dir,
        mask_dir=mask_dir,  # æ–°å¢
        building_class_id=building_class_id,  # æ–°å¢
        tree_class_id=tree_class_id,  # æ–°å¢
        normalization_method=normalization_method,
        enable_augmentation=enable_augmentation,
        stats_json_path=stats_json_path,
        height_filter=height_filter,
        force_recompute=force_recompute
    )
    
    dataloader = torch.utils.data.DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True if shuffle else False
    )
    dataloader.height_normalizer = dataset.height_normalizer
    return dataloader, dataset


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # è®¾ç½®é«˜åº¦è¿‡æ»¤å™¨ï¼Œé™åˆ¶åœ¨åˆç†èŒƒå›´å†…
    height_filter = {
        'min_height': -5.0,   # æœ€å°é«˜åº¦ï¼š-5ç±³
        'max_height': 100.0   # æœ€å¤§é«˜åº¦ï¼š100ç±³
    }
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå¸¦maskï¼‰
    dataloader, dataset = create_gamus_dataloader(
        image_dir='/path/to/images',
        label_dir='/path/to/labels',
        mask_dir='/path/to/classes',  # æ–°å¢ï¼šclassesç›®å½•
        building_class_id=6,          # æ–°å¢ï¼šå»ºç­‘ç±»åˆ«ID
        tree_class_id=5,              # æ–°å¢ï¼šæ ‘æœ¨ç±»åˆ«ID
        batch_size=8,
        shuffle=True,
        normalization_method='percentile',
        enable_augmentation=True,
        stats_json_path='./gamus_stats.json',
        height_filter=height_filter,
        force_recompute=False
    )
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
    stats = dataset.get_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    for batch_idx, (images, labels, masks) in enumerate(dataloader):
        print(f"æ‰¹æ¬¡ {batch_idx}: å½±åƒ {images.shape}, æ ‡ç­¾ {labels.shape}, mask {masks.shape}")
        print(f"maskç»Ÿè®¡: min={masks.min():.3f}, max={masks.max():.3f}, mean={masks.mean():.3f}")
        if batch_idx >= 2:  # åªæµ‹è¯•å‰å‡ ä¸ªæ‰¹æ¬¡
            break