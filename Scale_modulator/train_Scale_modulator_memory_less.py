#!/usr/bin/env python3
"""
å†…å­˜ä¼˜åŒ–ç‰ˆGAMUS nDSMè®­ç»ƒè„šæœ¬
ä¸“æ³¨äºå‡å°‘å†…å­˜å ç”¨ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
"""

import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import ReduceLROnPlateau
import numpy as np
import logging
import time
import argparse
import warnings
from datetime import datetime
from tqdm import tqdm
import json
from sklearn.metrics import mean_squared_error, mean_absolute_error
import gc
import psutil
warnings.filterwarnings('ignore')

# å¯¼å…¥ä¼˜åŒ–çš„æ¨¡å—
from improved_dataset_optimized import create_gamus_dataloader  # ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬
from improved_normalization_loss import create_height_loss
from Scale_Modulator import create_gamus_model

def setup_logger(log_path):
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    logger = logging.getLogger('gamus_training')
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_path, mode='w', encoding='utf-8')
    console_handler = logging.StreamHandler()
    
    # æ ¼å¼åŒ–å™¨
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆGBï¼‰"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    return memory_info.rss / 1024 / 1024 / 1024  # è½¬æ¢ä¸ºGB

def create_datasets(args, logger):
    """åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›† - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
    logger.info("åˆ›å»ºæ•°æ®é›†ï¼ˆå†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼‰...")
    
    # æ„å»ºæ•°æ®è·¯å¾„
    train_image_dir = os.path.join(args.data_dir, 'images', 'train')
    train_label_dir = os.path.join(args.data_dir, 'height', 'train')
    val_image_dir = os.path.join(args.data_dir, 'images', 'val')
    val_label_dir = os.path.join(args.data_dir, 'height', 'val')
    
    logger.info(f"æ£€æŸ¥è®­ç»ƒæ•°æ®è·¯å¾„:")
    logger.info(f"  å›¾åƒç›®å½•: {train_image_dir}")
    logger.info(f"  æ ‡ç­¾ç›®å½•: {train_label_dir}")
    
    # éªŒè¯è·¯å¾„
    for path in [train_image_dir, train_label_dir]:
        if not os.path.exists(path):
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {path}")
        else:
            files = os.listdir(path)
            logger.info(f"  {path}: {len(files)} ä¸ªæ–‡ä»¶")
    
    # è®¾ç½®é«˜åº¦è¿‡æ»¤å™¨
    height_filter = {
        'min_height': args.min_height,
        'max_height': args.max_height
    }
    logger.info(f"é«˜åº¦è¿‡æ»¤å™¨: {height_filter}")
    
    # è®°å½•åˆ›å»ºå‰çš„å†…å­˜ä½¿ç”¨
    memory_before = get_memory_usage()
    logger.info(f"åˆ›å»ºæ•°æ®é›†å‰å†…å­˜ä½¿ç”¨: {memory_before:.1f} GB")
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
    logger.info("æ­£åœ¨åˆ›å»ºè®­ç»ƒæ•°æ®é›†...")
    try:
        train_loader, train_dataset = create_gamus_dataloader(
            image_dir=train_image_dir,
            label_dir=train_label_dir,
            batch_size=args.batch_size,
            shuffle=True,
            normalization_method=args.normalization_method,
            enable_augmentation=args.enable_augmentation,
            stats_json_path=args.stats_json_path,
            height_filter=height_filter,
            force_recompute=args.force_recompute_stats,
            num_workers=args.num_workers,
            max_memory_samples=args.max_memory_samples  # é™åˆ¶ç»Ÿè®¡è®¡ç®—çš„æ ·æœ¬æ•°
        )
        height_normalizer = train_dataset.height_normalizer
        logger.info("âœ“ è®­ç»ƒæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        
        # è®°å½•åˆ›å»ºåçš„å†…å­˜ä½¿ç”¨
        memory_after = get_memory_usage()
        logger.info(f"åˆ›å»ºæ•°æ®é›†åå†…å­˜ä½¿ç”¨: {memory_after:.1f} GB (+{memory_after - memory_before:.1f} GB)")
        
    except Exception as e:
        logger.error(f"åˆ›å»ºè®­ç»ƒæ•°æ®é›†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise
    
    # åˆ›å»ºéªŒè¯æ•°æ®é›†
    val_loader = None
    if os.path.exists(val_image_dir) and os.path.exists(val_label_dir):
        logger.info("æ­£åœ¨åˆ›å»ºéªŒè¯æ•°æ®é›†...")
        try:
            val_loader, _ = create_gamus_dataloader(
                image_dir=val_image_dir,
                label_dir=val_label_dir,
                batch_size=args.batch_size,
                shuffle=False,
                normalization_method=args.normalization_method,
                enable_augmentation=False,
                height_filter=height_filter,
                num_workers=max(1, args.num_workers // 2),  # éªŒè¯é›†ä½¿ç”¨æ›´å°‘worker
                max_memory_samples=args.max_memory_samples // 2  # éªŒè¯é›†ä½¿ç”¨æ›´å°‘æ ·æœ¬
            )
            logger.info(f"âœ“ éªŒè¯æ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(val_loader.dataset)} ä¸ªæ ·æœ¬")
        except Exception as e:
            logger.error(f"åˆ›å»ºéªŒè¯æ•°æ®é›†å¤±è´¥: {e}")
            val_loader = None
    else:
        logger.warning("æœªæ‰¾åˆ°éªŒè¯é›†ï¼Œå°†ä½¿ç”¨è®­ç»ƒé›†è¿›è¡ŒéªŒè¯")
    
    logger.info(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    logger.info(f"æ•°æ®èŒƒå›´: [{height_filter['min_height']}, {height_filter['max_height']}] ç±³")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    logger.info("æµ‹è¯•æ•°æ®åŠ è½½...")
    try:
        test_batch = next(iter(train_loader))
        logger.info(f"âœ“ æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸ: å›¾åƒ {test_batch[0].shape}, æ ‡ç­¾ {test_batch[1].shape}")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        del test_batch
        gc.collect()
        
    except Exception as e:
        logger.error(f"æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        raise
    
    return train_loader, val_loader, train_dataset, height_normalizer

class SimpleGAMUSValidator:
    """å†…å­˜ä¼˜åŒ–çš„GAMUSéªŒè¯å™¨"""
    
    def __init__(self, height_normalizer, logger=None):
        self.height_normalizer = height_normalizer
        self.logger = logger or logging.getLogger(__name__)
        
    def denormalize_height(self, normalized_data):
        """ä½¿ç”¨å½’ä¸€åŒ–å™¨å°†å½’ä¸€åŒ–çš„nDSMæ•°æ®è¿˜åŸåˆ°çœŸå®é«˜åº¦å€¼"""
        return self.height_normalizer.denormalize(normalized_data)
    
    def validate_with_metrics(self, model, val_loader, criterion, device, epoch=None, max_batches=50):
        """æ‰§è¡ŒéªŒè¯å¹¶è¿”å›è¯¦ç»†æŒ‡æ ‡ - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
        model.eval()
        
        total_loss = 0.0
        total_count = 0
        
        # å¤§å¤§å‡å°‘æ”¶é›†çš„æ ·æœ¬æ•°é‡
        all_preds_real = []
        all_targets_real = []
        max_samples = 10000  # è¿›ä¸€æ­¥å‡å°‘æ ·æœ¬æ•°é‡
        
        memory_before = get_memory_usage()
        
        with torch.no_grad():
            pbar = tqdm(val_loader, desc=f'Validation', leave=False)
            
            for batch_idx, (images, labels) in enumerate(pbar):
                # é™åˆ¶éªŒè¯æ‰¹æ¬¡æ•°é‡ä»¥èŠ‚çœæ—¶é—´å’Œå†…å­˜
                if batch_idx >= max_batches:
                    break
                    
                images = images.to(device, non_blocking=True)
                labels = labels.to(device, non_blocking=True)
                
                try:
                    # å‰å‘ä¼ æ’­
                    predictions = model(images)
                    
                    # æ£€æŸ¥é¢„æµ‹å€¼
                    if torch.isnan(predictions).any() or torch.isinf(predictions).any():
                        self.logger.warning(f"é¢„æµ‹å€¼åŒ…å«æ— æ•ˆå€¼ï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                        continue
                    
                    # è®¡ç®—æŸå¤±
                    loss = criterion(predictions, labels)
                    
                    # æ£€æŸ¥æŸå¤±å€¼
                    if torch.isnan(loss) or torch.isinf(loss):
                        self.logger.warning(f"æŸå¤±å€¼æ— æ•ˆï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                        continue
                    
                    total_loss += loss.item()
                    total_count += 1
                    
                    # æ”¶é›†å°‘é‡æ ·æœ¬ç”¨äºæŒ‡æ ‡è®¡ç®—
                    if len(all_preds_real) < max_samples and batch_idx % 5 == 0:  # æ¯5ä¸ªæ‰¹æ¬¡é‡‡æ ·ä¸€æ¬¡
                        # è½¬æ¢ä¸ºnumpyå¹¶åå½’ä¸€åŒ–
                        preds_cpu = predictions.detach().cpu().numpy().flatten()
                        targets_cpu = labels.detach().cpu().numpy().flatten()
                        
                        # è¿›ä¸€æ­¥é‡‡æ ·ä»¥èŠ‚çœå†…å­˜
                        n_samples = min(100, len(preds_cpu))  # æ¯ä¸ªæ‰¹æ¬¡æœ€å¤š100ä¸ªæ ·æœ¬
                        if len(preds_cpu) > n_samples:
                            indices = np.random.choice(len(preds_cpu), n_samples, replace=False)
                            preds_cpu = preds_cpu[indices]
                            targets_cpu = targets_cpu[indices]
                        
                        # åå½’ä¸€åŒ–åˆ°çœŸå®é«˜åº¦
                        try:
                            preds_real = self.denormalize_height(preds_cpu)
                            targets_real = self.denormalize_height(targets_cpu)
                            
                            all_preds_real.extend(preds_real)
                            all_targets_real.extend(targets_real)
                        except Exception as e:
                            self.logger.warning(f"åå½’ä¸€åŒ–å¤±è´¥: {e}")
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({'loss': f'{loss.item():.6f}'})
                    
                    # ç«‹å³æ¸…ç†GPUå†…å­˜
                    del predictions, loss
                    if device.type == 'cuda':
                        torch.cuda.empty_cache()
                    
                except Exception as e:
                    self.logger.warning(f"éªŒè¯æ‰¹æ¬¡ {batch_idx} é”™è¯¯: {e}")
                    continue
                finally:
                    # æ¸…ç†CPUå†…å­˜
                    del images, labels
                    if batch_idx % 10 == 0:
                        gc.collect()
        
        memory_after = get_memory_usage()
        self.logger.debug(f"éªŒè¯åå†…å­˜ä½¿ç”¨: {memory_after:.1f} GB")
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / total_count if total_count > 0 else float('inf')
        
        # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
        metrics = {'loss': avg_loss}
        
        if all_preds_real and all_targets_real:
            all_preds_real = np.array(all_preds_real)
            all_targets_real = np.array(all_targets_real)
            
            # ç§»é™¤æ— æ•ˆå€¼
            valid_mask = (~np.isnan(all_preds_real) & ~np.isnan(all_targets_real) & 
                         ~np.isinf(all_preds_real) & ~np.isinf(all_targets_real))
            
            if np.sum(valid_mask) > 10:
                valid_preds = all_preds_real[valid_mask]
                valid_targets = all_targets_real[valid_mask]
                
                # åŸºç¡€æŒ‡æ ‡
                mae = mean_absolute_error(valid_targets, valid_preds)
                mse = mean_squared_error(valid_targets, valid_preds)
                rmse = np.sqrt(mse)
                
                # RÂ²
                ss_res = np.sum((valid_targets - valid_preds) ** 2)
                ss_tot = np.sum((valid_targets - np.mean(valid_targets)) ** 2)
                r2 = 1 - (ss_res / ss_tot) if ss_tot > 1e-10 else 0.0
                
                # ç²¾åº¦æŒ‡æ ‡
                errors = np.abs(valid_preds - valid_targets)
                accuracy_1m = np.mean(errors <= 1.0)
                accuracy_2m = np.mean(errors <= 2.0)
                accuracy_5m = np.mean(errors <= 5.0)
                
                metrics.update({
                    'mae': mae,
                    'mse': mse,
                    'rmse': rmse,
                    'r2': r2,
                    'accuracy_1m': accuracy_1m,
                    'accuracy_2m': accuracy_2m,
                    'accuracy_5m': accuracy_5m,
                    'valid_samples': len(valid_preds),
                    'data_range': f'[{valid_targets.min():.1f}, {valid_targets.max():.1f}]m'
                })
        
        # æ¸…ç†å†…å­˜
        del all_preds_real, all_targets_real
        gc.collect()
        
        return metrics
    
    def log_metrics(self, epoch, metrics, is_best=False):
        """è®°å½•æŒ‡æ ‡"""
        self.logger.info(f'éªŒè¯æŒ‡æ ‡ - Epoch {epoch}:')
        self.logger.info(f'  æŸå¤±: {metrics.get("loss", "N/A"):.6f}')
        if 'mae' in metrics:
            self.logger.info(f'  MAE: {metrics["mae"]:.4f} m')
            self.logger.info(f'  RMSE: {metrics["rmse"]:.4f} m')
            self.logger.info(f'  RÂ²: {metrics["r2"]:.4f}')
            self.logger.info(f'  ç²¾åº¦: Â±1m={metrics["accuracy_1m"]:.1%}, Â±2m={metrics["accuracy_2m"]:.1%}, Â±5m={metrics["accuracy_5m"]:.1%}')
            self.logger.info(f'  æ•°æ®èŒƒå›´: {metrics["data_range"]}, æœ‰æ•ˆæ ·æœ¬: {metrics["valid_samples"]}')
        
        if is_best:
            self.logger.info('  â˜… æœ€ä½³éªŒè¯æ€§èƒ½ â˜…')

def validate_model_enhanced(model, val_loader, criterion, device, logger, height_normalizer, epoch=None):
    """å¢å¼ºçš„éªŒè¯å‡½æ•° - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
    if val_loader is None:
        return {'loss': 0.0, 'count': 0}
    
    # åˆ›å»ºç®€åŒ–çš„éªŒè¯å™¨
    validator = SimpleGAMUSValidator(height_normalizer, logger)
    
    # æ‰§è¡ŒéªŒè¯ï¼ˆé™åˆ¶æ‰¹æ¬¡æ•°é‡ï¼‰
    max_batches = min(50, len(val_loader))  # æœ€å¤šéªŒè¯50ä¸ªæ‰¹æ¬¡
    metrics = validator.validate_with_metrics(model, val_loader, criterion, device, epoch, max_batches)
    
    # è®°å½•æŒ‡æ ‡
    validator.log_metrics(epoch, metrics)
    
    return metrics

def train_epoch(model, train_loader, criterion, optimizer, device, logger, epoch, memory_check_interval=50):
    """è®­ç»ƒä¸€ä¸ªepoch - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
    model.train()
    total_loss = 0.0
    total_count = 0
    
    memory_start = get_memory_usage()
    logger.info(f"Epoch {epoch} å¼€å§‹ï¼Œå†…å­˜ä½¿ç”¨: {memory_start:.1f} GB")
    
    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')
    
    for batch_idx, (images, labels) in enumerate(pbar):
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)
        
        try:
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            predictions = model(images)
            
            # æ£€æŸ¥é¢„æµ‹å€¼
            if torch.isnan(predictions).any() or torch.isinf(predictions).any():
                logger.warning(f"é¢„æµ‹å€¼åŒ…å«æ— æ•ˆå€¼ï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                continue
            
            # è®¡ç®—æŸå¤±
            loss = criterion(predictions, labels)
            
            # æ£€æŸ¥æŸå¤±å€¼
            if torch.isnan(loss) or torch.isinf(loss) or loss > 10:
                logger.warning(f"å¼‚å¸¸æŸå¤±å€¼ {loss.item():.6f}ï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                continue
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            # ä¼˜åŒ–å™¨æ­¥éª¤
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_count += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f'{loss.item():.6f}',
                'avg_loss': f'{total_loss/total_count:.6f}'
            })
            
            # ç«‹å³æ¸…ç†å†…å­˜
            del predictions, loss
            
            # å®šæœŸæ¸…ç†å†…å­˜
            if batch_idx % memory_check_interval == 0:
                if device.type == 'cuda':
                    torch.cuda.empty_cache()
                gc.collect()
                
                # æ£€æŸ¥å†…å­˜ä½¿ç”¨
                current_memory = get_memory_usage()
                if current_memory > memory_start + 2.0:  # å¦‚æœå†…å­˜å¢é•¿è¶…è¿‡2GB
                    logger.warning(f"å†…å­˜ä½¿ç”¨å¢é•¿è¾ƒå¤§: {current_memory:.1f} GB (+{current_memory - memory_start:.1f} GB)")
                    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
            
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                logger.error(f"GPUå†…å­˜ä¸è¶³: {e}")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                continue
            else:
                logger.error(f"è®­ç»ƒé”™è¯¯: {e}")
                continue
        except Exception as e:
            logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
            continue
        finally:
            # ç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡åéƒ½æ¸…ç†
            del images, labels
    
    avg_loss = total_loss / total_count if total_count > 0 else float('inf')
    
    memory_end = get_memory_usage()
    logger.info(f"Epoch {epoch} è®­ç»ƒå®Œæˆ - å¹³å‡æŸå¤±: {avg_loss:.6f}, å†…å­˜ä½¿ç”¨: {memory_end:.1f} GB")
    
    return avg_loss

def save_checkpoint(epoch, model, optimizer, loss, save_dir, is_best=False):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'timestamp': datetime.now().isoformat()
    }
    
    # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
    latest_path = os.path.join(save_dir, 'latest_checkpoint.pth')
    torch.save(checkpoint, latest_path)
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if is_best:
        best_path = os.path.join(save_dir, 'best_model.pth')
        torch.save(checkpoint, best_path)
        return best_path
    
    # å®šæœŸä¿å­˜
    if epoch % 10 == 0:
        epoch_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')
        torch.save(checkpoint, epoch_path)
    
    return latest_path

def main():
    parser = argparse.ArgumentParser(description='å†…å­˜ä¼˜åŒ–ç‰ˆGAMUS nDSMè®­ç»ƒè„šæœ¬')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--data_dir', type=str, required=True,
                        help='æ•°æ®æ ¹ç›®å½• (åŒ…å«imageså’Œheightå­ç›®å½•)')
    parser.add_argument('--save_dir', type=str, default='./checkpoints',
                        help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--stats_json_path', type=str, default=None,
                        help='é¢„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=4,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_epochs', type=int, default=20,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning_rate', type=float, default=5e-5,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--num_workers', type=int, default=1,  # é»˜è®¤å‡å°‘workeræ•°é‡
                        help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    
    # å†…å­˜ä¼˜åŒ–å‚æ•°
    parser.add_argument('--max_memory_samples', type=int, default=500,  # æ–°å¢ï¼šé™åˆ¶ç»Ÿè®¡è®¡ç®—æ ·æœ¬æ•°
                        help='ç”¨äºç»Ÿè®¡è®¡ç®—çš„æœ€å¤§æ ·æœ¬æ•°ï¼ˆå‡å°‘å†…å­˜å ç”¨ï¼‰')
    parser.add_argument('--memory_check_interval', type=int, default=50,
                        help='å†…å­˜æ£€æŸ¥é—´éš”ï¼ˆæ‰¹æ¬¡æ•°ï¼‰')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--normalization_method', type=str, default='minmax',
                        choices=['minmax', 'percentile', 'zscore'],
                        help='å½’ä¸€åŒ–æ–¹æ³•')
    parser.add_argument('--min_height', type=float, default=-5.0,
                        help='æœ€å°é«˜åº¦è¿‡æ»¤å€¼ï¼ˆç±³ï¼‰')
    parser.add_argument('--max_height', type=float, default=100.0,
                        help='æœ€å¤§é«˜åº¦è¿‡æ»¤å€¼ï¼ˆç±³ï¼‰')
    parser.add_argument('--enable_augmentation', action='store_true',
                        help='å¯ç”¨æ•°æ®å¢å¼º')
    parser.add_argument('--force_recompute_stats', action='store_true',
                        help='å¼ºåˆ¶é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--debug', action='store_true',
                        help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--encoder', type=str, default='vitb',
                        choices=['vits', 'vitb', 'vitl'],
                        help='ç¼–ç å™¨ç±»å‹')
    parser.add_argument('--pretrained_path', type=str, default='/home/hudong26/hudong26/Height/Depth-Anything-V2/checkpoints/depth_anything_v2_vitb.pth',
                        help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--freeze_encoder', action='store_true',
                        help='å†»ç»“ç¼–ç å™¨')
    
    # æŸå¤±å‡½æ•°å‚æ•°
    parser.add_argument('--loss_type', type=str, default='mse',
                        choices=['mse', 'mae', 'huber', 'focal', 'combined'],
                        help='æŸå¤±å‡½æ•°ç±»å‹')
    parser.add_argument('--height_aware', action='store_true',
                        help='å¯ç”¨é«˜åº¦æ„ŸçŸ¥æŸå¤±')
    
    # è®­ç»ƒæ§åˆ¶
    parser.add_argument('--patience', type=int, default=10,
                        help='å­¦ä¹ ç‡è°ƒåº¦å™¨è€å¿ƒå€¼')
    parser.add_argument('--early_stopping_patience', type=int, default=5,
                        help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--val_interval', type=int, default=1,
                        help='éªŒè¯é—´éš”')
    
    # è®¾å¤‡å‚æ•°
    parser.add_argument('--device', type=str, default='auto',
                        help='è®­ç»ƒè®¾å¤‡')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(args.save_dir, f'training_{timestamp}.log')
    logger = setup_logger(log_file)
    
    # è®¾ç½®è°ƒè¯•æ¨¡å¼
    if args.debug:
        logger.setLevel(logging.DEBUG)
    
    # æ‰“å°ç³»ç»Ÿä¿¡æ¯
    logger.info("=" * 60)
    logger.info("å†…å­˜ä¼˜åŒ–ç‰ˆGAMUS nDSMè®­ç»ƒ")
    logger.info("=" * 60)
    logger.info(f"ç³»ç»Ÿå†…å­˜: {psutil.virtual_memory().total / 1024**3:.1f} GB")
    logger.info(f"å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / 1024**3:.1f} GB")
    logger.info(f"å½“å‰å†…å­˜ä½¿ç”¨: {get_memory_usage():.1f} GB")
    logger.info(f"é…ç½®å‚æ•°: {json.dumps(vars(args), indent=2, ensure_ascii=False)}")
    
    # è®¾å¤‡è®¾ç½®
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    if device.type == 'cuda':
        logger.info(f"GPUä¿¡æ¯: {torch.cuda.get_device_name()}")
        logger.info(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        train_loader, val_loader, train_dataset, height_normalizer = create_datasets(args, logger)
        
        # åˆ›å»ºæ¨¡å‹
        logger.info("åˆ›å»ºæ¨¡å‹...")
        model = create_gamus_model(
            encoder=args.encoder,
            pretrained_path=args.pretrained_path,
            freeze_encoder=args.freeze_encoder,
            enable_scale_modulator=True
        ).to(device)
        
        # ç»Ÿè®¡æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        logger.info(f"æ¨¡å‹å‚æ•°: æ€»æ•°={total_params:,}, å¯è®­ç»ƒ={trainable_params:,}")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = AdamW(
            [p for p in model.parameters() if p.requires_grad],
            lr=args.learning_rate,
            weight_decay=1e-4
        )
        
        # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = ReduceLROnPlateau(
            optimizer,
            mode='min',
            factor=0.5,
            patience=args.patience,
            min_lr=1e-6,
            verbose=True
        )
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        criterion = create_height_loss(
            loss_type=args.loss_type,
            height_aware=args.height_aware
        )
        
        # è®°å½•è®­ç»ƒå¼€å§‹åçš„å†…å­˜ä½¿ç”¨
        memory_after_init = get_memory_usage()
        logger.info(f"æ¨¡å‹åˆå§‹åŒ–åå†…å­˜ä½¿ç”¨: {memory_after_init:.1f} GB")
        
        # è®­ç»ƒå¾ªç¯
        logger.info("å¼€å§‹è®­ç»ƒ...")
        best_val_loss = float('inf')
        patience_counter = 0
        start_time = time.time()
        
        for epoch in range(1, args.num_epochs + 1):
            # è®­ç»ƒ
            train_loss = train_epoch(
                model, train_loader, criterion, optimizer, device, logger, epoch, args.memory_check_interval
            )
            
            # éªŒè¯
            if epoch % args.val_interval == 0:
                val_metrics = validate_model_enhanced(
                    model, val_loader, criterion, device, logger, height_normalizer, epoch
                )
                val_loss = val_metrics['loss']
                
                # å­¦ä¹ ç‡è°ƒåº¦
                scheduler.step(val_loss)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best = val_loss < best_val_loss
                if is_best:
                    best_val_loss = val_loss
                    patience_counter = 0
                else:
                    patience_counter += 1
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                saved_path = save_checkpoint(
                    epoch, model, optimizer, val_loss, args.save_dir, is_best
                )
                
                # æ‰“å°ç»“æœ
                current_memory = get_memory_usage()
                logger.info(f"Epoch {epoch}/{args.num_epochs} ç»“æœ:")
                logger.info(f"  è®­ç»ƒæŸå¤±: {train_loss:.6f}")
                logger.info(f"  å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")
                logger.info(f"  å†…å­˜ä½¿ç”¨: {current_memory:.1f} GB")
                logger.info(f"  {'ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹!' if is_best else ''}")
                logger.info(f"  ä¿å­˜è·¯å¾„: {saved_path}")
                logger.info("-" * 60)
                
                # æ—©åœæ£€æŸ¥
                if patience_counter >= args.early_stopping_patience:
                    logger.info(f"æ—©åœè§¦å‘ (patience: {patience_counter})")
                    break
            
            # æ¯ä¸ªepochåæ¸…ç†å†…å­˜
            if device.type == 'cuda':
                torch.cuda.empty_cache()
            gc.collect()
        
        # è®­ç»ƒå®Œæˆ
        total_time = time.time() - start_time
        final_memory = get_memory_usage()
        logger.info(f"è®­ç»ƒå®Œæˆ!")
        logger.info(f"æ€»è€—æ—¶: {total_time / 3600:.2f} å°æ—¶")
        logger.info(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
        logger.info(f"æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_memory:.1f} GB")
        logger.info(f"æ¨¡å‹ä¿å­˜åœ¨: {args.save_dir}")
        
    except KeyboardInterrupt:
        logger.info("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†
        if device.type == 'cuda':
            torch.cuda.empty_cache()
        gc.collect()
        logger.info("è®­ç»ƒè„šæœ¬å·²é€€å‡º")

if __name__ == '__main__':
    main()